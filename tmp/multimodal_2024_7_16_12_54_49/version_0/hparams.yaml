config:
  batch_size: 64
  decay_power: 1
  drop_rate: 0.1
  end_lr: 0
  exp_name: multimodal
  fast_dev_run: false
  hidden_size: 768
  image_size: 224
  learning_rate: 3.0e-07
  load_path: /dvmm-filer3a/users/kevin/temporal-relations/result/multimodal_2024_3_16/version_0/checkpoints/epoch=31-step=223295.ckpt
  log_dir: tmp
  lr_mult: 1
  masking_prob: 0.0
  masking_type: image
  max_epoch: 50
  max_text_len: 40
  num_frames: 3
  num_gpus: 2
  num_heads: 12
  num_layers: 12
  num_nodes: 1
  num_workers: 15
  optim_type: adamw
  per_gpu_batchsize: 16
  precision: 16
  resume_from: None
  seed: 0
  shared_embedding_dim: 512
  test_only: true
  use_clip: false
  use_git: false
  val_check_interval: 1.0
  vit: vit_base_patch16_224
  vocab_size: 30522
  warmup_steps: 0.1
  weight_decay: 0.4
